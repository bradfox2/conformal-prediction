{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aangelopoulos/conformal-prediction/blob/main/notebooks/toxic-text-outlier-detection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cached data from Detoxify model on Jigsaw dataset. See https://github.com/unitaryai/detoxify for details.\n",
    "# The comments are from Wikipedia talk channels, and we are trying perform outlier detection\n",
    "# We will only use the non-toxic data, and then with type-1 error control identify the toxic outliers.\n",
    "if not os.path.exists(\"../data\"):\n",
    "    os.system(\"gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz\")\n",
    "    os.system(\"tar -xf ../data.tar.gz -C ../\")\n",
    "    os.system(\"rm ../data.tar.gz\")\n",
    "\n",
    "data = np.load(\"../data/toxic-text/toxic-text-detoxify.npz\")\n",
    "preds = data[\"preds\"]  # Toxicity score in [0,1]\n",
    "toxic = data[\"labels\"]  # Toxic (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "alpha = 0.1  # 1-alpha is the desired type-1 error\n",
    "n = 10000  # Use 200 calibration points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at only the non-toxic data\n",
    "nontoxic = toxic == 0\n",
    "preds_nontoxic = preds[nontoxic]\n",
    "preds_toxic = preds[np.invert(nontoxic)]\n",
    "\n",
    "# Split nontoxic data into calibration and validation sets (save the shuffling)\n",
    "idx = np.array([1] * n + [0] * (preds_nontoxic.shape[0] - n)) > 0\n",
    "np.random.shuffle(idx)\n",
    "cal_scores, val_scores = preds_nontoxic[idx], preds_nontoxic[np.invert(idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformal outlier detection happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the outlier detection method to get a threshold on the toxicities\n",
    "qhat = np.quantile(cal_scores, np.ceil((n + 1) * (1 - alpha)) / n)\n",
    "# Perform outlier detection on the ind and ood data\n",
    "outlier_ind = val_scores > qhat  # We want this to be no more than alpha on average\n",
    "outlier_ood = (\n",
    "    preds_toxic > qhat\n",
    ")  # We want this to be as large as possible, but it doesn't have a guarantee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type-1 error is 0.1078, the type-2 error is 0.2848, and the threshold is 0.4592.\n"
     ]
    }
   ],
   "source": [
    "# Calculate type-1 and type-2 errors\n",
    "type1 = outlier_ind.mean()\n",
    "type2 = 1 - outlier_ood.mean()\n",
    "print(\n",
    "    f\"The type-1 error is {type1:.4f}, the type-2 error is {type2:.4f}, and the threshold is {qhat:.4f}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unflagged text examples:\n",
      "[' Ув. Divot, Вы реагируете слишком эмоционально на безобидный словарь. И в этой эмоциональности случайно ))) выпячиваете проармянскую ТЗ. Вы, должно быть, хотите сказать, что станете вводить слова  погром  во все статьи о погромах, а не только в сумгатский? Ведь Вы позиционируете себя как нейтрального участника, не так ли? Я не стану возражать. А пока, на мой взгляд, в статье, Вашими усилиями и усилиями Ваших товарищей, висят целые разделы о том, как армянские террористы убивали, взрывали и т.д. а вот, смотрите, их оправдали. Значит, поделом, убитым и взорванным, заслужили! Главное ведь цель, заставить окружающих считаться со своим мнением путем. А цель достигнута. Прямо ода терроризму! У читателя при чтении такого материала явно возникнет мнение не только о допустимости терроризма, но даже о его целесообразности. Вы этого хотите? Извините, но у меня складывается именно такое представление, наблюдая Вашу настойчивость в откатах определения термина  терроризм . ', 'Merhaba ben Çuvaşyadan, Türkçe çok güzel bilmerim onun için inglizce yazıyorum. I think you should use turk name İdil/İtil/Etil/Edil/İdel/Atăl instead of using Russian name Volga. All turkish speaking peaple use one name with different pronouncation, why are Turkish are so special and use Russian name instead of Turkish, it seams stupid to me.', ' Глубину я не считаю показателем качества. ) Ладно, проанализируем. Откинем заливки. 341-100=241 в Польской, 132-20=112 в Русской. Более, чем в два раза. Средняя величина статьи, конечно, у Русской больше, но общий объем статей больше в Польской. Насчет феномена, он есть. ) И не в Гугле дело. Дело в том, что неплохо взять уже успешный опыт Польской Вики и попробывать хотя бы частично внедрить в Русскую. ) Да, мало в Воронеже википедистов. А сколько в Польше городов больше Воронежа? Варшава и Краков? Но тем не менее активность намного выше. Pauk ', 'Già non hai risposto al mio messaggio del 2 febbraio... Ma almeno un  grazie  per aver salvato la tua voce Duck Tales - Il tempo è denaro integrandola in Episodi di DuckTales (seconda stagione)... no? Hanno abolito il Wikilove? ;) Chesare T (msg) ', 'Atatürk tepki çekmemek için ne sağ ne sol olduğunu söylemiştir.Ama Atatürk yenilikçi olduğu gibi ekonomi biçimi (devletçilik)de sol ekonomi biçimidir.Yani atatürk bal gibi solcudur.Çarşıhastası ']\n",
      "\n",
      "\n",
      "Flagged text examples:\n",
      "['Ну, видимо, автор хотел сказать, что вот в мифах народов мира, дескать, описано применение осознанных сновидений для пророчества. Хотя это, конечно, фигня какая-то. Что за эпос? Конкретно что? Если вещие сны, то они как бы и не осознанные обычно. Да и вообще - дурацкая фраза. ', 'toi tu vas te faire engueuler par fugace si tu lui laisses ca comme message. Enfin, bienvenue parmi nous. Maloq causer ', ' não é gozação sua, é? Tu não mandas medalha a ninguém! Por que justamente a mim? Ou se esqueceu que tu não vais com a minha cara?    Golongo       . ..    ', 'Вы недовно заблокировали участника Crow на 2 часа. Судя по всему оная блокировка ему на пользу не пошла и он продолжает заниматься оскорблениями и провоцированиями участников. Меня в частности. Поскольку общаться с этим господином по типу  сам ты дурак  мне впадлу, то может вы примете превентивные меры для недопущения дальнейших оскорблений? Дифф: А.Соколов ', 'Quindi gli altri dicono  cazzate  e tu sei il custode dei  veri criteri  sui calciatori? Ma che discussione è? In quella discussione la maggior parte degli intervenuti non ha ritenuto sufficienti le presenze registrate fino a questo momento, inferiori alla soglia che tu stesso hai indicato.   Kōji         parla con me      ']\n"
     ]
    }
   ],
   "source": [
    "# Show some examples of unflagged and flagged text\n",
    "content = pd.read_csv(\"../generation-scripts/toxic_text_utils/test.csv\")[\"content\"]\n",
    "print(\"Unflagged text examples:\")\n",
    "print(list(np.random.choice(content[preds <= qhat], size=(5,))))\n",
    "print(\"\\n\\nFlagged text examples:\")\n",
    "print(list(np.random.choice(content[preds > qhat], size=(5,))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
